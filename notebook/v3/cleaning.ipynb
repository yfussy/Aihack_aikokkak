{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b86149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fc7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "from fileDir import getDataDir, getModelDir, getPredDir\n",
    "from modules.v1.xgboostModel import trainTestXgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0baa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 3\n",
    "TRAIN_PATH = getDataDir(\"train\")\n",
    "TEST_PATH = getDataDir(\"test\")\n",
    "CLEANED_TRAIN_PATH = getDataDir(\"train\", VERSION)\n",
    "CLEANED_TEST_PATH = getDataDir(\"test\", VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a42394",
   "metadata": {},
   "source": [
    "## Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a60bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataset(df, cleanPath):\n",
    "    # Drop unnecessary columns (keep ID)\n",
    "    drop_cols = ['pms_i_ymd','Area','Province','Shop Name','date_of_birth_week','marital_status',\n",
    "                 'c_postal_code','nummber_of_resident','c_number_of_employee', 'media',\n",
    "                 'place_for_sending_information','r_generalcode4', 'r_generalcode5']\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # Combine year/month features safely\n",
    "    if {'living_period_month','living_period_year'}.issubset(df.columns):\n",
    "        df['living_period_month'] = df['living_period_month'].fillna(0) + df['living_period_year'].fillna(0) * 12\n",
    "        df.drop(columns=['living_period_year'], inplace=True)\n",
    "\n",
    "    if {'c_number_of_working_month','c_number_of_working_year'}.issubset(df.columns):\n",
    "        df['c_number_of_working_month'] = df['c_number_of_working_month'].fillna(0) + df['c_number_of_working_year'].fillna(0) * 12\n",
    "        df.drop(columns=['c_number_of_working_year'], inplace=True)\n",
    "\n",
    "    # Convert birth date to age\n",
    "    if 'date_of_birth' in df.columns:\n",
    "        df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], errors='coerce')\n",
    "        df['age'] = 2025 - df['date_of_birth'].dt.year\n",
    "        df.drop(columns=['date_of_birth'], inplace=True)\n",
    "\n",
    "    # Ensure numeric columns are numeric\n",
    "    num_cols = ['number_of_children','living_period_month','c_date_of_salary_payment',\n",
    "                'c_monthly_salary','c_number_of_working_month','r_expected_credit_limit',\n",
    "                'r_allloan_case','r_allloan_amount','r_additional_income','r_spouse_income','age']\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    num_cols = [c for c in num_cols if c in df.columns]\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "    # Fill categorical columns\n",
    "    cat_cols = ['gender','tel_category','type_of_residence','postal_code',\n",
    "                'c_business_type','c_position','c_occupation','c_employment_status',\n",
    "                'c_salary_payment_methods','r_propose','r_generalcode1','r_generalcode2',\n",
    "                'r_generalcode3','apply']\n",
    "    df.replace([\"NaN\", \"nan\", \"None\", \"\"], np.nan, inplace=True)\n",
    "    for c in cat_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna('Unknown')\n",
    "\n",
    "    print(df.head(3))\n",
    "    df.to_csv(cleanPath, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec86cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID gender  number_of_children  postal_code  tel_category  \\\n",
      "0  2.024120e+11     F2                   2        10400             3   \n",
      "1  2.024120e+11      M                   0        10500             3   \n",
      "2  2.024120e+11     F2                   0        10170             3   \n",
      "\n",
      "   number_of_resident  living_period_month  type_of_residence  \\\n",
      "0                   2                   60                  6   \n",
      "1                   3                   48                  6   \n",
      "2                   6                   62                  3   \n",
      "\n",
      "   c_business_type  c_position  ...  r_allloan_case  r_allloan_amount  \\\n",
      "0                7           5  ...               0                 0   \n",
      "1                7           5  ...               0                 0   \n",
      "2                7           4  ...               1             10000   \n",
      "\n",
      "   r_additional_income  r_spouse_income  r_generalcode1  r_generalcode2  \\\n",
      "0                  0.0              0.0         Unknown         Unknown   \n",
      "1               5000.0              0.0         Unknown         Unknown   \n",
      "2                  0.0              0.0         Unknown         Unknown   \n",
      "\n",
      "   r_generalcode3 apply  default_12month  age  \n",
      "0             2.0    WI                0   54  \n",
      "1             1.0    WI                0   42  \n",
      "2             1.0    DS                0   33  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "             ID gender  number_of_children  postal_code  tel_category  \\\n",
      "0  202412000196     F2                   2        10120             3   \n",
      "1  202412000241     F2                   0        10120             3   \n",
      "2  202412000242     F2                   0        10120             3   \n",
      "\n",
      "   number_of_resident  living_period_month  type_of_residence  \\\n",
      "0                   4                  108                  6   \n",
      "1                   5                   38                  6   \n",
      "2                   1                   24                  6   \n",
      "\n",
      "   c_business_type  c_position  ...  r_propose  r_allloan_case  \\\n",
      "0                7           5  ...        5.0             0.0   \n",
      "1                4           5  ...        5.0             3.0   \n",
      "2                4           5  ...        5.0             2.0   \n",
      "\n",
      "   r_allloan_amount  r_additional_income  r_spouse_income  r_generalcode1  \\\n",
      "0                 0                  0.0          17000.0             1.0   \n",
      "1             20000                  0.0          12700.0             1.0   \n",
      "2             17000               1000.0              0.0         Unknown   \n",
      "\n",
      "   r_generalcode2 r_generalcode3  apply  age  \n",
      "0             4.0            1.0     WI   44  \n",
      "1             3.0            2.0     WI   32  \n",
      "2         Unknown            2.0     WI   49  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "ids = test_df[\"ID\"].copy()\n",
    "\n",
    "train_df = cleanDataset(train_df, CLEANED_TRAIN_PATH)\n",
    "test_df = cleanDataset(test_df, CLEANED_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb3566",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c7075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE applied. Imbalance ratio before: 6.72\n",
      "GPU detected -> using XGBoost GPU training (gpu_hist).\n",
      "Tuning hyperparameters with early stopping (using validation set)...\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainTestXgboost(VERSION, train_df, test_df, ids)\n",
      "File \u001b[1;32md:\\CU\\Aihack_aikokkak\\modules\\v1\\xgboostModel.py:166\u001b[0m, in \u001b[0;36mtrainTestXgboost\u001b[1;34m(version, train_df, test_df, ids)\u001b[0m\n\u001b[0;32m    160\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_set\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(X_valid, y_valid)],\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    163\u001b[0m }\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuning hyperparameters with early stopping (using validation set)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 166\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train_res, y_train_res, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    167\u001b[0m best_model \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters Found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1952\u001b[0m         ParameterSampler(\n\u001b[0;32m   1953\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1954\u001b[0m         )\n\u001b[0;32m   1955\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Toa\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainTestXgboost(VERSION, train_df, test_df, ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
